model:
  arch: "FPN"
  backbone: "timm-regnetx_032"
  pretrained_weights: "imagenet"
  out_layer_size: 512
  in_channels: 3
  version: "2"

data:
  folder_structure: "separate_json" # separate, separate_json, unified
  dataset: "bmw_support_images"
  input_size: 224
  nb_classes: 2

  crop_image:
      status: 0
      x_min: 0
      y_min: 0
      x_max: 0
      y_max: 0
      
  augmentations:
  
    ShiftScaleRotate:
      shift_limit: 0.4
      scale_limit: 0.4
      rotate_limit: 180
      probability: 0.5

    RGBShift:
      r_shift_limit: 50
      g_shift_limit: 50
      b_shift_limit: 50
      probability: 0.3

    RandomBrightnessContrast:
      brightness_limit: 0.3
      contrast_limit: 0.3
      probability: 0.3

training:
  optimizer: "Lion"
  load_opt: False
  criterion: 'ProxyAnchor' # CrossEntropyLoss2d | DiceLoss | FocalLoss | CrossEntropyDiceLoss | BinaryCrossEntropyWithLogits2d
  epochs: 25
  batch_size: 16
  learning_rate: 0.00001
  device: "cuda"
  num_workers: 4

finetune:
  epochs: 100
  learning_rate: 0.001

proxy_anchor:
  alpha: 32
  margin: 0.8
  lr: 0.01
  steps: 500

inference:
  device: "cuda"
  num_of_neighbors: 2
  threshold: 0.0

#-- Guidance for models' configuration --#
#  model = UNet(
#      num_classes=cfg.model.num_classes,
#      in_channels=3,
#      freeze_bn=cfg.model.freeze_bn
#  )

#  model = UNetResnet(
#      num_classes=cfg.model.num_classes,
#      in_channels=3,
#      backbone=cfg.model.backbone,
#      pretrained=True,
#      freeze_bn=cfg.model.freeze_bn,
#      freeze_backbone=cfg.model.freeze_backbone
#  )

#  model = DeepLab(
#      num_classes=cfg.model.num_classes,
#      in_channels=3,
#      backbone=cfg.model.backbone,
#      pretrained=True,
#      output_stride=cfg.model.output_stride,
#      freeze_bn=cfg.model.freeze_bn,
#      freeze_backbone=cfg.model.freeze_backbone
#  )

#  model = DeepLabX(
#      num_classes=cfg.model.num_classes,
#      in_channels=3,
#      backbone=cfg.model.backbone,
#      pretrained=True,
#      output_stride=cfg.model.output_stride,
#      freeze_bn=cfg.model.freeze_bn,
#      freeze_backbone=cfg.model.freeze_backbone
#  )

sam:
  debug: True # to use this mode, run in normal mode first to get npy files and crops
  visualise: False # visualize sam inference
  sam_model_name: "vit_h"
  sam_model_path: r"C:\Users\nikita.karpuks\.cache\torch\hub\checkpoints\sam_vit_h_4b8939.pth"
  model:
    backbone: ResNet # ViT, ResNet, EffNetV2, SqueezeNet, ConvNext, SwinTransformer
    arch: resnet101
    # ResNet          -> resnet18, resnet34, resnet50, resnet101, resnet152
    # ViT             -> vit_b_16, vit_b_32, vit_l_16, vit_l_32
    # EffNetV2        -> efficientnet_v2_s, efficientnet_v2_m, efficientnet_v2_l
    # SwinTransformer -> tiny, small, base
    # ConvNext        -> tiny, small, base, large
    emb_size_reduction_status: False
    emb_size_reduction_heads: 1
    embedding_size: 512
    freeze_backbone: False
    min_mask_region_area: 500
  data:
    root_path: "./sam"
    threshold_orig_overlap: 0.1 # if overlap is bigger then sam mask will be filtered
    min_area: 10 # in pixels
    epsilon: 0.001
    n_clusters: 30
    preprocessing:
      pad_to_square: 1
      input_size: 224
      normalize:
        p: 0
  training:
    device: "cpu"
    batch_size: 1
    num_workers: 0